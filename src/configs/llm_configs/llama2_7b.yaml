llm_name: "llama2_7b"
model_load_config:
  model_name_or_path: "meta-llama/Llama-2-7b-hf"
  tokenizer_name: "meta-llama/Llama-2-7b-hf"
  load_in_4bit: True
  use_bfloat: True
translation_prompts: None
generation_params:
  num_beams: 5
  max_new_tokens: 5
  length_penalty: -1.0
