llm_name: "llama3_8b_instruct"
model_load_config:
  model_name_or_path: "meta-llama/Meta-Llama-3-8B-Instruct"
  tokenizer_name: "meta-llama/Meta-Llama-3-8B-Instruct"
  load_in_4bit: True
  use_bfloat: True
use_chat_template: True