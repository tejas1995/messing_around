llm_name: "mistral_7b_instruct"
model_load_config:
  model_name_or_path: "mistralai/Mistral-7B-Instruct-v0.2"
  tokenizer_name: "mistralai/Mistral-7B-Instruct-v0.2"
  load_in_4bit: True
  use_bfloat: True
use_chat_template: True